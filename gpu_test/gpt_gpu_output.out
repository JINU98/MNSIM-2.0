------------------------------------
Configuration Information:
------------------------------------
Mon Nov 25 23:12:56 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-16GB           Off |   00000000:3B:00.0 Off |                    0 |
| N/A   32C    P0             35W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Tesla V100-PCIE-16GB           Off |   00000000:D8:00.0 Off |                    0 |
| N/A   28C    P0             35W /  250W |       0MiB /  16384MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Date: Mon Nov 25 23:12:56 EST 2024
Time: 23:12:56
OS: Linux
Kernel: 3.10.0-514.2.2.el7.x86_64
Memory: 191844 MB
GPU Model: Tesla V100-PCIE-16GB
Tesla V100-PCIE-16GB
GPU Driver Version: 550.54.15
550.54.15
CUDA Version: V12.1.66  
Python Version: Python 3.9.20
NumPy Version: 1.26.4
PyTorch Version: 2.4.1
Project Directory: /work/jmalekar/MNSIM-2.0
PWD: /work/jmalekar/MNSIM-2.0/gpu_test
GPUs: 0
CPUS: 28
HOST: node387
Python: /work/jmalekar/MNSIM-2.0/gpu_test/env/bin/python
CONDA: /work/jmalekar/MNSIM-2.0/gpu_test/env
Partition: gpu-v100-16gb
Job ID: 17781644
User: jmalekar
Running command:
python test_gpu_gpt.py

------------------------------------
------------------------------------

Profiling gpt2
  Sequence length: 64
    Attention Layer Latency: 0.165415 seconds
    Overall Model Latency: 2.196959 seconds
  Sequence length: 128
    Attention Layer Latency: 0.000337 seconds
    Overall Model Latency: 0.006504 seconds
  Sequence length: 256
    Attention Layer Latency: 0.000229 seconds
    Overall Model Latency: 0.006835 seconds
  Sequence length: 512
    Attention Layer Latency: 0.000337 seconds
    Overall Model Latency: 0.007828 seconds
  Sequence length: 1024
    Attention Layer Latency: 0.000241 seconds
    Overall Model Latency: 0.010467 seconds

Profiling gpt2-medium
  Sequence length: 64
    Attention Layer Latency: 0.000497 seconds
    Overall Model Latency: 0.021039 seconds
  Sequence length: 128
    Attention Layer Latency: 0.000243 seconds
    Overall Model Latency: 0.011584 seconds
  Sequence length: 256
    Attention Layer Latency: 0.000235 seconds
    Overall Model Latency: 0.011246 seconds
  Sequence length: 512
    Attention Layer Latency: 0.000241 seconds
    Overall Model Latency: 0.011361 seconds
  Sequence length: 1024
    Attention Layer Latency: 0.000264 seconds
    Overall Model Latency: 0.020007 seconds

Profiling gpt2-large
  Sequence length: 64
    Attention Layer Latency: 0.000544 seconds
    Overall Model Latency: 0.017029 seconds
  Sequence length: 128
    Attention Layer Latency: 0.000241 seconds
    Overall Model Latency: 0.016457 seconds
  Sequence length: 256
    Attention Layer Latency: 0.000239 seconds
    Overall Model Latency: 0.015854 seconds
  Sequence length: 512
    Attention Layer Latency: 0.000226 seconds
    Overall Model Latency: 0.016194 seconds
  Sequence length: 1024
    Attention Layer Latency: 0.000230 seconds
    Overall Model Latency: 0.028631 seconds

Profiling gpt2-xl
  Sequence length: 64
    Attention Layer Latency: 0.000498 seconds
    Overall Model Latency: 0.025075 seconds
  Sequence length: 128
    Attention Layer Latency: 0.000240 seconds
    Overall Model Latency: 0.030037 seconds
  Sequence length: 256
    Attention Layer Latency: 0.000232 seconds
    Overall Model Latency: 0.022328 seconds
  Sequence length: 512
    Attention Layer Latency: 0.000262 seconds
    Overall Model Latency: 0.022538 seconds
  Sequence length: 1024
    Attention Layer Latency: 0.000243 seconds
    Overall Model Latency: 0.285314 seconds
Elapsed Time for  stage (D:H:M:S:MS): 0:0:0:28:583
------------------------------------
------------------------------------

